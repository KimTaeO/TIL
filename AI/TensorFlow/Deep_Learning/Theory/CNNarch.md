## CNN 아키텍쳐

* CNN은 컨볼루션층을 거쳐 완전연결층을 거쳐 출력층으로 연결되는데 컨볼루션층이 은닉층의 역할을 대신한다

* 컨볼루션 계층 구조

    * conv 부분은 가중치들의 집합인 다양한 필터의 입력데이터의 특징을 추출하는 역할을 수행하고

    * ReLU 부분은 입력으로 주어지는 값이 양수이면 그대로 내보내고 음수라면 0을 반환하는 역할을 한다

    * pooling 부분은 입력으로 주어지는 정보를 ```최대값, 최솟값, 평균값``` 등으로 압축하여 데이터의 연산량을 줄여주는 역할을 한다

        * Max pooling : 데이터 중에서 가장 큰 값만을 기억

        * Min pooling : 데이터 중에서 가장 작은 값만을 기억

        * Average pooling : 데이터의 평균값을 기억

* 컨볼루션 연산 : 입력데이터를 필터링해 가중치의 집합체를 뽑아내 컨볼루션 연산을 하여 바이어스 값을 뽑아내어 특징 맵을 만든다

## 패딩 

* 컨볼루션 연산을 수행하기 전에 입력 데이터 주변을 특정 값으로 채우는 것을 말하며 컨볼루션 연산에서도 자주 이용되는 방법이다

* 컨볼루션 연산을 수행하면 데이터 크기가 줄어드는 단점을 방지하기 위해 사용한다

## CNN 특징 추출기(Feature Exactor) + 분류기(Classifier)

* 이미지를 분류하기 위해서 사용되는 일반적인 CNN 구조는 특징 추출기(Feature Exactor)와 분류기(Classifier)가 합쳐져 있는 형태이다

    * 특징 추출기 : 컨볼루션 레이어(Conv Layer)와 풀링 레이어(Pooling Layer)등의 다양한 조합으로 구성되며, 말 그대로 이미지 데이터의 특징을 추출하고 압축하는 역할을 수행한다

        * Conv : API로는 Conv2D를 사용하고, Conv Layer를 나타내기 위해(높이, 너비, 채널) 형태의 텐서로 주어지는 input_shape를 사용하며 kernel_size, filters 는 반드시 기술되어야 한다

        * Pool : API로는 MaxPool2D를 사용하고, 한번에 Max_Pooling을 수행할 범위를 pool_size에 나타냄


    * Flat Layer : API로는 Flatten() 을 사용하고 ,특징 추출기의 출력은 (높이, 너비, 채널)로 나타나는 3차원 텐서이므로, 완전연결층인 Dense Layer와 이어지기 위해서는 3차원 텐서를 1차원 vector로 만들어주는 역할을 수행한다


    * 분류기 : 완전연결층인 Dense Layer와 과적합을 방지하기 위한 Dropout Layer등의 다양한 조합으로 구성되며 정답을 분류하는 역할을 수행한다

        * Dense : API로는 Dense(1st para, 2nd para)신경망에서 은닉층과 출력층을 의미하는 완전연결층을 나타내고 1st para에서는 출력층 노드 수를, 2nd para 에서는 활성화 함수인 activation=""을 사용한다

        * Dropout : API로는 Dropout(rate = n)을 사용하며 학습과정중에 지정된 비율만큼 랜덤하게 Layer과 Layer 사이의 연결을 끊어서 네트워크의 과적합(overfitting)을 막는 역할을 수행함

## CNN의 오버피팅을 낮추고 정확도를 높이는법

* 더 많은 Layer 쌓기
    Conv Layer가 더 중첩된 더 깊은 구조가 될 수록 성능은 크게 개선된다

* 이미지 데이터 보강(Image Data Augmentation)
    딥러닝에서는 많은 학습 데이터를 사용하면 성능을 개선시킬 수 있다

    기존의 이미지 데이터가 있을 때, 해당 데이터를 원본으로 하여 다양한 변형을 주고 그 데이터를 원본 파일에 포함시키면 많은 학습 데이터를 확보할 수 있다

* 높은 해상도(High Resolution)의 학습 데이터 확보
    동일한 CNN구조라면 상대적으로 높은 해상도의 학습데이터를 통해서 성능을 개선시킬 수 있다

* L1 Norm, L2 Norm등의 가중치 규제(Regularization), Dropout 배치 정규화(Batch Normalization) 등을 통해 성능을 개선시킬 수 있음 